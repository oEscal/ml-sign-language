\section{Conclusões}
Finalizado este estudo, foi nos possível consolidar o nosso conhecimento relativamente aos algoritmos mais populares usados em \textit{Machine learning}, mais especificamente em processos de classificação multi-classe. 
O foco deste trabalho foi fazer um \textit{Feature engineering} dos hiperparâmetros de entrada de cada algoritmo, baseando-se no processo sistemático de tentativa e erro de experimentar várias gamas de cada parâmetro, estudando-se os resultados e eficácia dos mesmos tentando perceber e justificar as respectivas performances com apoios em gráficos, outros estudos ou formulas matemáticas.
Pelo facto de termos uma grande quantidade de dados, decidimos implementar e estudar algoritmos como redes neuronais e \textit{SVM} já que estes têm uma grande efectividade nestes casos.
Foi possível concluir que especificamente para este \textit{dataset}, usar algoritmos mais complexos como é o caso das redes neuronais e \textit{SVM} tornou-se \textit{overkill}, uma vez que o algoritmo de \textit{Logisitc Regression} obteve óptimos resultados, muito melhores do que aqueles que esperávamos inicialmente. Isto pode ser justificado pelas mesmas razões do \textit{MNIST} ser um \textit{dataset} fácil de obter modelos que tenham uma boa performance: pelo facto de serem \textit{datasets} simples, em que as imagens a serem analisadas se encontram em escala cinza, centradas e sem variações extremas, modelos tão simples como Regressão Logística têm a capacidade de gerar resultados com bastante qualidade.
Para além disso, durante o estudo notamos que muitas vezes não houve \textit{overfit} em modelos em que esperávamos ter acontecido. Como consequência, foi-nos impossível testar o papel da alteração do parâmetro de regularização nas Redes Neuronais, já que esta só é necessária quando há \textit{overfit}. Isto poderá dever-se ao facto deste \textit{dataset} ser o resultado de processos de \textit{data augmentation} sobre um \textit{dataset} inicial de menores dimensões, pelo que quando os nossos modelos foram treinados, foram logo colocados sobre todos os possíveis dados, pelo que quando submetidos aos dados de teste e validação, estes não apresentaram muitas novidades.
