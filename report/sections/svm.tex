\section{Support Vector Machine (SVM)}
SVM é um algoritmo simples, capaz de produzir taxas de sucesso elevadas com um poder computacional reduzido, apesar dos tempos de execução serem elevados devido à grande quantidade de \textit{samples}.
Após alguma pesquisa, confirmamos que \textit{SVM} tem um desempenho bom para problemas de análise de imagens, muito pelo facto de este ser efectivo em espaços dimensionais grandes, que neste caso são o número de pixeis de cada imagem (784).
O objectivo deste algoritmo é encontrar um \textit{hyperplane} (\textit{decision boundary}) num espaço N-dimensional que distinga os dados fornecidos, onde será preferido o \textit{hyperplane} cujo valor da margem seja maior.
\newline 
Devido ao que foi referido anteriormente, decidimos usar os \textit{kernels} que nos pontos seguintes irão ser descritos.


\subsection{\textbf{RBF Kernel}}
Antes de partir à análise desta \textit{kernel} em específico, iremos fazer um pré balanço generalizado da mesma.

O parâmetro \textit{gamma} define a região de influência que um determinado exemplo de treino atinge, tendo o significado de "longe" se o valor for baixo e "perto" se o valor for alto.
O algoritmo é muito sensível a mudanças deste parâmetro, por isso é fulcral que este seja o mais adequado possível, não podendo ser muito pequeno, com o risco de \textit{underfit} (pois a região de influência de qualquer \textit{support vector} irá incluir o \textit{dataset} na totalidade) e não podendo ser muito elevado, com o risco de \textit{overfit} (pois a região de influência de qualquer \textit{support vector} irá incluir apenas o próprio \textit{support vector}. Obviamente o que foi descrito em cima só é valido se hipoteticamente os valores de \textit{gamma} pudessem ser $(-\infty, +\infty)$, respectivamente.
O gráfico \ref{fig:gamma_values_influence} ilustra a influência dos valores de \textit{gamma}.
Para complementar os dados definidos anteriormente, iremos mostrar um \textit{heat map} \ref{fig:heat_map} da \textit{cross validation accuracy} em função de \textit{C} e \textit{gamma}. Como se pode visualizar, os valores que se encontram na diagonal tendem a providenciar um modelo com melhor \textit{accuracy}.


\begin{figure}[!t]
\centering
\includegraphics[width=3in]{figures/gamma_values.png}
\caption{Visualização da influência dos valores de \textit{gamma}}
\label{fig:gamma_values_influence}
\end{figure}


\begin{figure}[!t]
\centering
\includegraphics[width=3in]{figures/heatmap.png}
\caption{\textit{HeatMap} da \textit{Cross validation accuracy} em função de \textit{C} e \textit{gamma}}
\label{fig:heat_map}
\end{figure}



\subsubsection{Valores \textit{default} dos hiperparâmetros}

\begin{itemize}
    \item \textit{gamma} = 0.1
    \item \textit{C} = 1
\end{itemize}

Apenas de referir que a ordem de treino dos hiperparâmetros foi a seguinte:
\begin{itemize}
    \item \textit{gamma}
    \item \textit{C}
\end{itemize}


\subsubsection{Equação da \textit{Gaussian radial basis function}}
\ref{gaussian_kernel}
\begin{equation}
	k(\textbf{xi},\textbf{xj}) = \exp{(-\gamma  \left \| \textbf{xi} - \textbf{xj}   \right \|^{2})}
    \label{gaussian_kernel}
\end{equation}




\subsubsection{Estudo da variação do \textit{gamma}}
Definimos como primeira abordagem a atribuição de valores mais desfasados de \textit{gamma}, sendo o leque de valores o seguinte: \ref{gamma_values}.\newline
O erro do \textit{train set} e \textit{cross validation set} obtidos neste modelo para a variação do parâmetro \textit{gamma} pode ser observados no gráfico \ref{fig:model_gamma}.
Como se pode observar ambos os erros têm valores muito próximos o que indica que o algoritmo obteve uma performance bastante boa.\newline
Para complementar a análise feita a este algoritmos será apresentado o  gráfico \ref{fig:time_operations_gama} de tempos das operações de \textit{fit} e \textit{predict}.\newline
Com a análise destes dados podemos inferir que este algoritmo em particular tem uma performance excelente em todos os dados disponíveis, e que neste caso o critério de desempate foi o tempo de execução das respectivas operações de \textit{fit} e \textit{predict} que tendem a diminuir com o aumento da performance do algoritmo que neste caso corresponde ao aumento do valor de \textit{gamma}. Isto justifica-se pelo facto de o algoritmo perder muito tempo a tentar criar um \textit{hyperplane} que se ajuste aos dados, não o conseguindo fazer eficientemente devido aos valores mal atribuídos dos hiperparâmetros.
Podemos chegar à conclusão que o aumento de \textit{gamma} permite a criação de um \textit{hyperplane} mais complexo capaz de capturar a forma dos dados, o que não se verifica com valores mais pequenos pois a região de influência de cada \textit{Support Vector} é maior causando maiores restrições no que toca à flexibilidade do modelo, causando o fenómeno de \textit{underfit}.
Por outro lado, se os valores de \textit{gamma} forem muito elevados, o algoritmo produz um \textit{hyperplane} demasiado complexo causando \textit{overfit}, como é visível no gráfico \ref{fig:model_gamma}, verificando-se o aumento drástico do \textit{cross validation error}.


\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/validation_curve_svmrbf_gamma.png}
\caption{Curva de validação para vários valores de \textit{gamma}}
\label{fig:model_gamma}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/time_per_parameter_gamma.png}
\caption{Tempo das operações de \textit{Fit} e \textit{Predict} dos modelos para vários valores de \textit{gamma}}
\label{fig:time_operations_gama}
\end{figure}

\begin{figure*}[!t]
\begin{equation}
    \gamma \in \{0.001, 0.002, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000\}
\label{gamma_values}
\end{equation}
\end{figure*}

\subsubsection{Estudo da variação do \textit{C} (1/\\lambda)}
Apenas de referir que o melhor parâmetro de \textit{gamma} foi usado no treino dos seguintes modelos, acompanhado o plano de selecção do melhor modelo.
O parâmetro \textit{C} comporta-se como um um parâmetro de regularização para o \textit{SVM}, na medida em que valores pequenos vão alargar a margem, ou seja uma função de decisão menos complexa será construída,verificando-se o oposto igualmente. Acaba por ser um parâmetro capaz de definir o \textit{trade-off} entre a correta classificação dos dados de treino e a maximização da margem da função de decisão.
Mais uma vez optamos pela definição de um conjunto de valores desfasados, capazes de gerar modelos cujos estudos consigam ser conclusivos. Os valores para este parâmetro são $\textit{C} \in \{0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 1, 5, 10, 50, 100, 500, 1000\}$.
Os \textit{erros} de \textit{train set} e \textit{cross validation set} obtidos neste modelo para a variação do parâmetro \textit{C} podem ser observados no gráfico \ref{fig:model_svm_C} e os tempos de execução dos processos de \textit{fit} e \textit{predict} no gráfico \ref{fig:time_operations_rbf_C}.

Como se pode observar para valores demasiados pequenos de \textit{C} o modelo acaba por não conseguir gerar um \textit{hyperPlane} suficientemente complexo que corresponda à forma dos dados, causando o fenómeno de \textit{underfit}. Mesmo para valores elevados de \textit{C} o \textit{Cross validation error} continua muito baixo acompanhado o erro do \textit{Train Set}.
Mais uma vez verificou-se que os tempos diminuem com o aumento da \textit{accuracy} do modelo, pelos mesmos motivos explicados anteriormente.


\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/validation_curve_svmrbf_C.png}
\caption{Curva de validação para vários valores de \textit{C}}
\label{fig:model_svm_C}
\end{figure}

 
\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/time_per_parameter_rbf_C.png}
\caption{Tempo das operações de \textit{Fit} e \textit{Predict} dos modelos para vários valores de \textit{C}}
\label{fig:time_operations_rbf_C}
\end{figure}


\subsubsection{Conclusões}
Através do estudo feito à \textit{SVM} com \textit{kernel} gaussiana, podemos concluir que o algoritmo é mais sensível às variações do parâmetro \textit{gamma}. Como se pode verificar no \textit{heatmap} anterior, mesmo que os valores de \textit{C} sejam ridiculamente altos a penalização na \textit{accuracy} no modelo não é muito grande caso o \textit{gamma} tenha os valores correctos, isto justifica-se pois este parâmetro actua como um parâmetro de regularização estrutural.

No final deste processo os melhores parâmetros foram os seguintes:
\begin{itemize}
    \item \textit{gamma} = 0.04
    \item \textit{C} = 5
\end{itemize}

Para obtermos o melhor modelo possível, realizamos um último processo de treino com os melhores parâmetros, sendo agora apresentadas as tabelas de métricas de performance \ref{tab: rbf_perfomance} e matriz de confusão \ref{tab: rbf_confusion_matrix}.


\begin{table}[!htp]
\caption{Métricas de performance para $\gamma = 0.04$ e $\textit{C} = 5$}
\begin{center}
\begin{tabular}{l c c c c}
\begin{tabular}{l c c c c}
Class & Accuracy & Recall & Precision & F1 Score\\ \hline
0 & 1.0 & 1.0 & 1.0 & 1.0\\
1 & 1.0 & 1.0 & 1.0 & 1.0\\
2 & 1.0 & 1.0 & 1.0 & 1.0\\
3 & 1.0 & 1.0 & 1.0 & 1.0\\
4 & 0.996 & 0.996 & 1.0 & 0.998\\
5 & 1.0 & 1.0 & 1.0 & 1.0\\
6 & 1.0 & 1.0 & 1.0 & 1.0\\
7 & 1.0 & 1.0 & 1.0 & 1.0\\
8 & 1.0 & 1.0 & 1.0 & 1.0\\
10 & 1.0 & 1.0 & 1.0 & 1.0\\
11 & 1.0 & 1.0 & 1.0 & 1.0\\
12 & 1.0 & 1.0 & 1.0 & 1.0\\
13 & 1.0 & 1.0 & 0.996 & 0.998\\
14 & 1.0 & 1.0 & 1.0 & 1.0\\
15 & 1.0 & 1.0 & 1.0 & 1.0\\
16 & 1.0 & 1.0 & 1.0 & 1.0\\
17 & 1.0 & 1.0 & 1.0 & 1.0\\
18 & 1.0 & 1.0 & 1.0 & 1.0\\
19 & 1.0 & 1.0 & 1.0 & 1.0\\
20 & 1.0 & 1.0 & 1.0 & 1.0\\
21 & 1.0 & 1.0 & 1.0 & 1.0\\
22 & 1.0 & 1.0 & 1.0 & 1.0\\
23 & 1.0 & 1.0 & 1.0 & 1.0\\
24 & 1.0 & 1.0 & 1.0 & 1.0\\
\hline
Macro Average & 1.0 & 1.0 & 1.0 & 1.0\\
\end{tabular}
\end{tabular}
\label{tab: rbf_perfomance}
\end{center}
\end{table}





\begin{table*}[!htp]
\caption{Matriz de confusão para $\gamma = 0.04$ e $\textit{C} = 5$}
\begin{center}
\setlength{\tabcolsep}{0.5em}
\begin{tabular}{l l|c c c c c c c c c c c c c c c c c c c c c c c c }
{} & {} & \multicolumn{24}{c}{Actual Class}\\
{} & Class&0&1&2&3&4&5&6&7&8&10&11&12&13&14&15&16&17&18&19&20&21&22&23&24\\
\hline
\multirow{24}{*}{\rotatebox[origin=c]{90}{ Predicted Class}}&1&0&291&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&2&0&0&281&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&3&0&0&0&282&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&4&0&0&0&0&277&0&0&0&0&0&0&0&1&0&0&0&0&0&0&0&0&0&0&0\\
&5&0&0&0&0&0&296&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&6&0&0&0&0&0&0&305&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&7&0&0&0&0&0&0&0&314&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&8&0&0&0&0&0&0&0&0&288&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&10&0&0&0&0&0&0&0&0&0&250&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&11&0&0&0&0&0&0&0&0&0&0&274&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&12&0&0&0&0&0&0&0&0&0&0&0&311&0&0&0&0&0&0&0&0&0&0&0&0\\
&13&0&0&0&0&0&0&0&0&0&0&0&0&281&0&0&0&0&0&0&0&0&0&0&0\\
&14&0&0&0&0&0&0&0&0&0&0&0&0&0&270&0&0&0&0&0&0&0&0&0&0\\
&15&0&0&0&0&0&0&0&0&0&0&0&0&0&0&272&0&0&0&0&0&0&0&0&0\\
&16&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&290&0&0&0&0&0&0&0&0\\
&17&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&289&0&0&0&0&0&0&0\\
&18&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&294&0&0&0&0&0&0\\
&19&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&309&0&0&0&0&0\\
&20&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&258&0&0&0&0\\
&21&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&287&0&0&0\\
&22&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&306&0&0\\
&23&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&291&0\\
&24&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&307\\
\end{tabular}

\label{tab: rbf_confusion_matrix}
\end{center}
\end{table*}



\subsection{\textbf{Polynomial Kernel}}
Antes da análise, apenas de referir que todos os balanços feitos anteriormente relativamente aos parâmetros \textit{C} e \textit{gamma} aplicam-se a esta análise.
Neste tipo de \textit{kernel} mais um parâmetro é usado, \textit{degree}. Este parâmetro é responsável pela flexibilidade da \textit{decision boundary} em que valores mais elevados cria uma função mais complexa.
\subsubsection{Valores \textit{default} dos hiperparâmetros}
\begin{itemize}
    \item \textit{C} = 1 
    \item \textit{degree} = 6
    \item \textit{gamma} = 1 / nFeatures
\end{itemize}

\subsubsection{Equação da \textit{kernel} polinomial}
\ref{polinomyal_kernel}

\begin{equation}
	r(\textbf{xi},\textbf{xj}) = (\textbf{xi}*\textbf{xj} + 1)^{d}
    \label{polinomyal_kernel}
\end{equation}

\subsubsection{Estudo da variação de \textit{C}(1/\\lambda)}
Os valores usados para este parâmetro foram $\textit{C} \in \{0.001, 0.002, 0.01, 0.02, 0.1, 0.2, 1, 5, 10, 50, 100, 500, 1000\}$.
Para ajudar na análise serão apresentados os gráficos de erro de \textit{Train set}, \textit{CV set},gráfico  \ref{fig:model_poly_C}, e os tempos de execução dos processos de \textit{fit} e \textit{predict},gráfico \ref{fig:time_operations_poly_C}.

Apesar de à primeira vista parecer que o fenómeno de \textit{overfit} está  a ocorrer, se analisarmos com mais detalhe podemos verificar que a diferença média entre os erros é muito baixa (0.002), o que indica uma boa performance destes modelos.
Além disso, podemos verificar que os erros apresentados são bastantes constantes o que indica que o valor \textit{default} de \textit{degree} possa ter influenciado a consistência deste estudo.
Comparativamente à \textit{kernel} anterior, os tempos do processos de \textit{fit} e \textit{predict} são muito menores o que acaba por ser uma vantagem.


\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/validation_curve_poly_C.png}
\caption{Curva de validação para vários valores de \textit{C}}
\label{fig:model_poly_C}
\end{figure}


\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/time_per_parameter_poly_C.png}
\caption{Tempo das operações de \textit{Fit} e \textit{Predict} dos modelos para vários valores de \textit{C}}
\label{fig:time_operations_poly_C}
\end{figure}


\subsubsection{Estudo da variação de \textit{degree}}
Aqui definimos o leque de valores de \textit{degree} como:  $\textit{degree} \in \{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18\}$.
Neste estudo foi usado o melhor parâmetro \textit{C}.
Como era de esperar, para valores muito grandes de \textit{degree} o fenómeno de \textit{overfit} tende a aparecer, pois uma função mais complexa acaba por ser criada moldando-se demasiado aos dados de treino não generalizando os outros casos.
Isto pode-se comprovar com a visualização do gráfico \ref{fig:model_poly_degree}, que apesar do erro estar a aumentar pouco, verificamos uma tendência de subida do \textit{cross validation error} com o aumento exagerado do valor de \textit{degree}.


\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/validation_curve_poly_degree.png}
\caption{Curva de validação para vários valores de \textit{degree}}
\label{fig:model_poly_degree}
\end{figure}


\begin{figure}[htp]
\centering
\includegraphics[width=3in]{figures/time_per_parameter_poly_degree.png}
\caption{Tempo das operações de \textit{Fit} e \textit{Predict} dos modelos para vários valores de \textit{degree}}
\label{fig:time_operations_poly_degree}
\end{figure}

\subsubsection{Notas}
Apenas de referir que apesar de neste tipo de \textit{kernel} ser possível variar o parâmetro \textit{gamma}, não o conseguimos fazer devido ao facto de a livraria que usamos para a realização deste estudo(\textit{sklearn}) ter um tempo de execução muito elevado (maior que dois dias), justificável por esta trabalhar com o \textit{CPU} o que limita muito na execução de serviços necessários nos processos de \textit{fit} e \textit{predict}.
Acreditamos mesmo assim, que as variações deste parâmetro tenham mais ou menos as mesmas implicações que na \textit{kernel} apresentada anteriormente.

\subsubsection{Conclusões}
Com o estudo desta \textit{kernel} foi possível verificar que este algoritmo mais uma vez é menos sensível às mudanças do parâmetro \textit{C}, como se pode verificar no gráfico \ref{fig:model_poly_C} ambos os erros mantêm-se inalterados muito por culpa do valor \textit{default} do parâmetro \textit{degree} (6). Apesar de este valor ter sido escolhido aleatoriamente verificou-se que com este valor o modelo tem um taxa de sucesso elevada, como é mostrado no gráfico \ref{fig:model_poly_degree} cujo o erro é praticamente 0, o que influenciou na consistência do gráfico \ref{fig:model_poly_C}.
Mais uma vez se verifica o fenómeno de \textit{overfit} caso os respectivos valores do parâmetro \textit{degree} sejam demasiado elevado, criando uma \textit{decision boundary} demasiado complexa.

No final deste processo os melhores parâmetros foram os seguintes:
\begin{itemize}
    \item \textit{C} = 0.01
    \item \textit{degree} = 3
\end{itemize}

Após o último processo de treino com os melhores parâmetros, obtivemos as seguintes tabelas: métricas de performance \ref{tab: poly_perfomance} e matriz de confusão \ref{tab: poly_confusion_matrix}.


\begin{table}[!htp]
\caption{Métricas de performance para \textit{C} = 0.01 e \textit{degree} = 3 }
\begin{center}
\begin{tabular}{l c c c c}
Class & Accuracy & Recall & Precision & F1 Score\\ \hline
0 & 1.0 & 1.0 & 1.0 & 1.0\\
1 & 1.0 & 1.0 & 1.0 & 1.0\\
2 & 1.0 & 1.0 & 1.0 & 1.0\\
3 & 1.0 & 1.0 & 1.0 & 1.0\\
4 & 1.0 & 1.0 & 1.0 & 1.0\\
5 & 1.0 & 1.0 & 1.0 & 1.0\\
6 & 1.0 & 1.0 & 1.0 & 1.0\\
7 & 1.0 & 1.0 & 1.0 & 1.0\\
8 & 1.0 & 1.0 & 1.0 & 1.0\\
10 & 1.0 & 1.0 & 1.0 & 1.0\\
11 & 1.0 & 1.0 & 1.0 & 1.0\\
12 & 1.0 & 1.0 & 1.0 & 1.0\\
13 & 1.0 & 1.0 & 1.0 & 1.0\\
14 & 1.0 & 1.0 & 1.0 & 1.0\\
15 & 1.0 & 1.0 & 1.0 & 1.0\\
16 & 1.0 & 1.0 & 1.0 & 1.0\\
17 & 1.0 & 1.0 & 1.0 & 1.0\\
18 & 1.0 & 1.0 & 1.0 & 1.0\\
19 & 1.0 & 1.0 & 1.0 & 1.0\\
20 & 1.0 & 1.0 & 1.0 & 1.0\\
21 & 1.0 & 1.0 & 1.0 & 1.0\\
22 & 1.0 & 1.0 & 1.0 & 1.0\\
23 & 1.0 & 1.0 & 1.0 & 1.0\\
24 & 1.0 & 1.0 & 1.0 & 1.0\\
\hline
Macro Average & 1.0 & 1.0 & 1.0 & 1.0\\
\end{tabular}
\label{tab: poly_perfomance}
\end{center}
\end{table}

\begin{table*}[!htp]
\caption{Matriz de confusão para \textit{C} = 0.01 e \textit{degree} = 3 }
\begin{center}
\setlength{\tabcolsep}{0.5em}
\begin{tabular}{l l|c c c c c c c c c c c c c c c c c c c c c c c c }
{} & {} & \multicolumn{24}{c}{Actual Class}\\
{} & Class&0&1&2&3&4&5&6&7&8&10&11&12&13&14&15&16&17&18&19&20&21&22&23&24\\
\hline
\multirow{24}{*}{\rotatebox[origin=c]{90}{ Predicted Class}}&0&301&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&1&0&291&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&2&0&0&281&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&3&0&0&0&282&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&4&0&0&0&0&278&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&5&0&0&0&0&0&296&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&6&0&0&0&0&0&0&305&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&7&0&0&0&0&0&0&0&314&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&8&0&0&0&0&0&0&0&0&288&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&10&0&0&0&0&0&0&0&0&0&250&0&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&11&0&0&0&0&0&0&0&0&0&0&274&0&0&0&0&0&0&0&0&0&0&0&0&0\\
&12&0&0&0&0&0&0&0&0&0&0&0&311&0&0&0&0&0&0&0&0&0&0&0&0\\
&13&0&0&0&0&0&0&0&0&0&0&0&0&281&0&0&0&0&0&0&0&0&0&0&0\\
&14&0&0&0&0&0&0&0&0&0&0&0&0&0&270&0&0&0&0&0&0&0&0&0&0\\
&15&0&0&0&0&0&0&0&0&0&0&0&0&0&0&272&0&0&0&0&0&0&0&0&0\\
&16&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&290&0&0&0&0&0&0&0&0\\
&17&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&289&0&0&0&0&0&0&0\\
&18&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&294&0&0&0&0&0&0\\
&19&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&309&0&0&0&0&0\\
&20&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&258&0&0&0&0\\
&21&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&287&0&0&0\\
&22&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&306&0&0\\
&23&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&291&0\\
&24&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&0&307\\
\end{tabular}
\label{tab: poly_confusion_matrix}
\end{center}
\end{table*}

\subsection{Trabalhos relacionados}
Actualmente existe uma quantidade enorme de estudos relacionados com o processo de \textit{model selection} pois este desempenha um papel fulcral no sucesso do resultado de um algoritmo de \textit{machine learning}. Novos e melhores critérios de selecção têm-se vindo a desenvolver, apesar de neste caso iremos filtrar estes métodos para aqueles aplicáveis em \textit{SVM}, ref \cite{model_selection}.
\begin{itemize}
    \item \textit{Empirical error criterion}: Neste critério de selecção são considerados um sub-conjunto do \textit{dataset} para fazer uma aproximação de risco do algoritmo.
    \item \textit{GACV}: Este critério é considerada uma estimativa pessimista do \textit{missclassification error}.  
    É obtido primeiramente uma aproximação com a função do tipo \textit{leaving-out} baseado numa probabilidade logarítmica negativa e de seguida passamos ao processo de substituição dos elementos diagonais de certas matrizes por trace/n (n=dimensão da matrix) \cite{GCVA}.
    \item  \textit{VC dimension criterion}: É estritamente proporcional ao limite da margem do raio, cuja formula é:
    \begin{equation}
        T = R^{2} * \left \| w \right \|^{2}
    \end{equation}{}
\end{itemize}
